

# ğŸ“§ TailMind â€” Smart Inbox + AI Email Agent

Your intelligent inbox that categorizes emails, extracts tasks, chats with email context, and generates professional drafts â€” all powered by Gemini LLM.

---

# ğŸŒ Project Overview

TailMind is a full-stack AI email assistant with:

### âœ”ï¸ AI-Based Email Categorization

Automatically classifies emails as **Important**, **Newsletter**, **Spam**, or **To-Do**.

### âœ”ï¸ Action Item Extraction

Uses LLM to pull structured tasks out of any email.

### âœ”ï¸ Smart Email Chatbox

Chat about any email (â€œsummarizeâ€, â€œwhat is the sender asking?â€, â€œgenerate replyâ€) with full context awareness.

### âœ”ï¸ Auto Draft Generation

One-click reply generation in customizable tones.

### âœ”ï¸ Prompt Brain

Editable prompts (categorization / extraction / email reply) stored in DB.

### âœ”ï¸ Beautiful Modern UI (React + Tailwind)

Inbox, email detail view, draft manager, chatbox.

---



---

# ğŸ—ï¸ Tech Stack

### **Frontend**

* React (Vite)
* TailwindCSS / shadcn components
* Axios API client

### **Backend**

* FastAPI
* SQLModel + SQLAlchemy
* PostgreSQL (Render)
* Google Gemini LLM (google-genai or google-generativeai SDK)

---

# ğŸ“ Project Structure

```
root/
â”‚â”€â”€ backend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â”œâ”€â”€ db.py
â”‚   â”‚   â”œâ”€â”€ models.py
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ llm_service.py
â”‚   â”‚   â”‚   â”œâ”€â”€ ingestion_service.py
â”‚   â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â”‚   â”œâ”€â”€ agent.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚
â”‚â”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ lib/api.js
â”‚   â”œâ”€â”€ index.html
â”‚
â”‚â”€â”€ README.md
â”‚â”€â”€ .env.example
```

---

# ğŸ”§ Backend Setup

### 1. Install dependencies

```
cd backend
pip install -r requirements.txt
```

### 2. Create `.env` file

```
GEMINI_API_KEY=your_key_here
GEMINI_MODEL=gemini-2.0-flash-exp
DATABASE_URL=postgresql://user:pass@host:5432/dbname
```

### 3. Run FastAPI server

```
uvicorn src.main:app --reload
```

Backend will run at:

```
http://localhost:8000
```

### 4. Access docs

Swagger:

```
http://localhost:8000/docs
```

ReDoc:

```
http://localhost:8000/redoc
```

---

# ğŸ¨ Frontend Setup

### 1. Install dependencies

```
cd frontend
npm install
```

### 2. Configure `.env`

```
VITE_API_URL=http://localhost:8000
```

### 3. Run frontend

```
npm run dev
```

App will run at:

```
http://localhost:5173
```

---

# ğŸš€ Deployment

### Backend (Render)

* Use **Python 3.10+**
* Add environment variables
* Add build command:

```
pip install -r backend/requirements.txt
```

* Start command:

```
uvicorn backend.src.main:app --host=0.0.0.0 --port=$PORT
```

### Frontend (Netlify / Vercel)

* Build command:

```
npm run build
```

* Set environment variable:

```
VITE_API_URL=https://your-backend-url.onrender.com
```

---

# ğŸ§  Key Features (Detailed)

### ğŸ” **Email Categorization**

* LLM predicts exactly one label
* Uses DB-stored prompt for full control
* Falls back to heuristics (optional)

### ğŸ§¾ **Task Extraction**

* Returns list of structured tasks:

```json
[
  { "task": "Review the contract", "deadline": "2024-06-10" },
  { "task": "Send feedback", "deadline": null }
]
```

### ğŸ¤– **Chat Agent**

* Context-aware responses
* Works with or without selected email
* Used by ChatBox UI

### ğŸ“ **Draft Generator**

* Returns:

```json
{
  "subject": "Re: [Original Subject]",
  "body": "Here is your professional reply..."
}
```

* Saved in DB
* Viewed in Drafts list and DraftDetail page

### ğŸ§© **Prompt Editor**

* Live updates to prompts
* Stored in DB
* Used instantly by LLM service

---

# ğŸ”Œ API Overview

Common routes:

### `/inbox`

Fetch all emails (with tasks, category, drafts).

### `/inbox/load`

Load mock emails (safe for testing).

### `/email/{id}`

Get details of one email.

### `/agent/chat`

Context-aware chat with LLM.

### `/agent/draft`

Generate reply draft.

### `/draft/generate`

Generate and store a draft.

### `/drafts`

Get all drafts.

### `/prompts`

Get or update prompt templates.

### `/process/reprocess`

Recompute categories + tasks for all emails.

---

# ğŸ§ª Development Tools

### Auto reload backend

```
uvicorn src.main:app --reload
```

### Pretty API logs

In `api.js` â†’ Axios interceptors already added.

---

# âš ï¸ Troubleshooting

### âŒ LLM not being used

Check:

```
/health â†’ llm: "available"
```

### âŒ Tasks always empty

Check LLM logs:

```
llm_service._call() logs
safe_json_extract() output
```

### âŒ Inbox not processing

Call:

```
POST /process/reprocess
```

### âŒ Cors issues

Frontend URL must match:

```
allow_origins=["*"] or frontend URL
```

---

# ğŸ“„ License

MIT â€” free to use, modify, deploy.

---

# ğŸ¤ Contributing

PRs welcome! You can improve:

* UI (shadcn components)
* New AI capabilities
* Attachments parsing
* Multi-account inbox sync

---

# ğŸ™Œ Credits

Built by **TailMind Team** â€” powered by Gemini LLM.
Backend (FastAPI), Frontend (React), DB (SQLModel/Postgres).
